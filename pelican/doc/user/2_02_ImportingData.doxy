/**

\page user_dataImporter Importing Data

\section importData_Intro Introduction

This section of the guide explains how to import data into Pelican
pipelines for subsequent processing, and introduces a number of key concepts
and components of the Pelican framework.

As well as being an introduction, this chapter includes a tutorial to
illustrate how to connect to a UDP data stream containing a signal, how to
build a very basic but fully-working Pelican pipeline to process the data, and
finally how to output the processed data. The tutorial will step through of a
number of code examples and explain the steps required to implement each
component.

First, we introduce some general terminology used in the Pelican framework.

\section importData_DataTypes Input Data Types

Pelican distinguishes between two classes of data, namely <em>Stream Data</em>
and <em>Service Data</em> (described below).
There can be any number of stream data and service data types, but each one
must be handled separately (each will need its own
\ref importData_Adapters "adapter" and \ref importData_Chunkers "chunker";
these components are described in later sections).
It is also possible to have multiple inputs of the same type.
Each source of incoming data, either stream or service, must have its own
unique identifier in the form of a string.

\subsection importData_StreamData Stream Data

This is an incoming data stream that is expected to be a fairly continuous
series of similarly structured data. As it arrives it is automatically
associated with any available service data.

\subsection importData_ServiceData Service Data

This is relatively static data that is updated occasionally and
supports the stream data (e.g. describing the incoming stream data format),
or status information of instruments collecting the data.
There is always a "current" version of any type of service data,
and it is this version that is associated with any incoming stream data.


\section importData_InputStream An Example Input Stream

To begin our tutorial, let's suppose that we have a source of input stream
data from a UDP socket on port 2000. The UDP packets are 1056 bytes long, and
each consists of a 32-byte header followed by 256 samples of 4-byte
floating-point values from a digitised time series. For this example, the
signal in the time series will be a simple sine wave.

The header contains the following fields:
- Header + 0: A four-byte integer containing the total size of the UDP packet, in bytes (1056).
- Header + 4: A four-byte integer containing the size of the header, in bytes (32).
- Header + 8: A four-byte integer containing the number of samples in the packet (256).
- Header + 12: A four-byte integer containing the size of a single sample, in bytes (4).
- Header + 16: An eight-byte integer containing a monotonically-increasing packet sequence number.

The remainder of the header data is reserved. Each sample represents 10
microseconds of data, so each UDP packet will arrive roughly every 2.56
milliseconds.

\subsection importData_Emulation Emulating Input Stream Data

This data stream can be emulated using the classes provided in the data
emulation framework.

\section importData_Chunkers Chunkers

A <em>chunker</em> is the first component of a functioning processing system.
Its purpose is to connect to a source of input data (for example, a network
socket, or a local file) and turn it into suitable size chunks. Each chunk of
data will be processed by one iteration of a single Pelican pipeline. Since the
input data rate may be high, a chunker should not, in general, attempt to
process, re-order or otherwise interpret the input data stream, but should
simply accumulate enough data to form a complete chunk. This may mean that
large chunks will need to be assembled from many smaller data packets, if the
chunker connects to a network socket. If the data needs to be rearranged for
optimal processing, then this rearrangement should be performed by the
\ref importData_Adapters "data adapter" (described in the next section).



... SignalChunker ...

----------------------------------------------

\section importData_Server Server
TODO Intro - what its used for.

\subsection importData_IntegratingChunkers Integrating Chunkers
TODO howto...

---------------------------

\section importData_UsingDataClients Methods of using the data clients
TODO Methods of using the direct stream and pelican server client....

\subsection importData_PelicanServerClient Pelican Server Client
\subsection importData_DirectStreamClient Direct Stream Client

TODO Data Client Example (tutorial) - using pelican server.

--------------------------------------------------


\section importData_Adapters Adapters

Adapters provide a mechanism to convert chunks of raw binary data into the data
members of a Pelican data-blob (a specialised C++ container for holding data
used by the Pelican pipeline; see \ref importData_DataBlobs "below").
The most basic functionality of an adapter is to de-serialise chunks of data,
although reordering and re-factoring of the data to a form that is convenient
for subsequent pipeline processing may also be carried out.
Pelican currently provides support for two categories of adapters,
distinguished by the type of input data chunks they are expected to process:
these are stream data adapters and service data adapters, which operate on the
relevant \ref importData_DataTypes "data types".

Adapters can be configured, if required, using parameters specified in the XML
configuration file. An adapter must inherit either the AbstractStreamAdapter
or the AbstractServiceAdapter class interface, depending on its type.

tutorial adapter SignalDataAdapter

\subsection importData_DataBlobs Data-Blobs

In Pelican, a data-blob is a well-structured representation of data that has
been arranged for easy, optimal processing: the output from an adapter is a
well-structured representation of the data held in a chunk, which is ready to
be processed by a pipeline. Data-blobs may contain arrays, blocks of memory
and/or other metadata, and should provide methods to interact with that data.
One of their main functions is to act as an interface between pipeline modules.

\subsection importData_TcpStreams TCP streams
TODO Reading the right number of bytes in the adapter when using TCP stream


---------------------------------------

\section inportData_Testing Testing Data Import
TODO ref emulators











============================================================================

\section user_dataImporter_introduction Introduction

This section describes how data can read into and prepared for use in Pelican.

The following sections of the reference documentation are relevant for
importing data into Pelican:

\li \link user_referenceChunkers Chunker reference\endlink
\li \link user_referenceDataBlobs Data Blob reference\endlink
\li \link user_referenceAdapters Adapter reference\endlink
\li \link user_referenceConfiguration Configuration reference\endlink

In order to test data import the Pelican test utility library provides a
\ref user_referenceEmulators "data emulation framework".


Each of these reference pages will provide an example of the classes you need
to implement, but before you delve into these it is important to understand
a few data related concepts described below.





\section user_dataImporter_overview Overview

To import data into the application you need to tell Pelican some important
details:
\li The type of socket the stream is on
\li The host and port of the stream
\li How to chop the data into units for processing (Chunking the data)
\li How to interpret the data stream (Adapting the data)

To do this you will need to implement two C++ classes, one for chunking and
one for data adaption. These classes slot into the Pelican framework to
deliver data to the pipeline.



@section dataClient The DataClient

Now that you have implemented your Chunker, Adapter and DataBlob classes,
you can now use them in a DataClient. A DataClient is an implementation
of the \em AbstractDataClient interface, which is the primary interface
used in by the processing pipeline for accessing the data when it needs
it.

Pelican provides two different DataClient implementations that you can configure
to your needs:
\li The \em PelicanServerClient connects to a Pelican server and so only
    requires an Adapter (the Chunker being in the Server itself).
\li The \em DirectStreamDataClient connects directly to the incoming
data stream and so needs both an Adapter and a Chunker.

These clients can be used directly by specifying adapters and chunkers in the XML
configuration file. Alternatively you can inherit from these classes to set
your adapters and chunkers as appropriate using the classes API. This later
method is recommended as it allows you to provide an "official" data interface
for your application with customised configuration options and sensible default
settings, allowing ease of reuse by pipeline developers.

\subsection specifyDataClient Specifying the DataClient to use
The PelicanApplication needs to know which data client will be used
for importing data. You specify the class by name, by calling the
\em setDataClient(const QString& dataClientName) method on the
\em PipelineApplication class.

e.g. for the DirectDataClientExample below you would use
\code
PipelineApplication* app; // initialised application
app->setDataClient("DirectDataClientExample");
\endcode


\subsection dataClientAdapter Installing an Adapter into a DataClient
\subsubsection dataClientAdapter_XML XML configuration to install an Adapter
\subsubsection dataClientAdapter_API Using the API to install an Adapter

\subsection dataClientChunkers Installing Chunkers into the DirectStreamDataClient
\subsubsection connecting_dataClientDirect_XML XML configuration options to install
a Chunker
\subsubsection connecting_dataClientDirect_API Inheriting from the DirectStreamDataClient
In the constructor of your DataClient call the \em addChunker()
method to attach your chunker to the named stream.

e.g.
\include DirectDataClientExample.h
\include DirectDataClientExample.cpp

In this example demonstrates how to attach two chunkers of the
same type to two differently named streams. The chunkers will be initialised
with the relevant XML chunk that corresponds to the chunker and has
the \em name parameter that corresponds to the final string passed to
\em addChunker.  By passing parameters through this config, you can setup
your chunker appropriately.

\section pelicanServer The Pelican Server
The Pelican Server requires you to specify one or more chunkers
and associate these chunkers to named one or more named data streams.

This is done via the \em addStreamChunker() and
\em addServiceChunker() methods of the \em PelicanServer
object. As the names suggest the former is used to associate chunkers
with data streams that are to be treated as stream data and the latter for
data that is to be treated as service data.

*/
