/**
@page user_framework_dataEssentials Data Import Essentials 

@section dataEssentials_overview Overview

This section of the guide is about reading in and preparing data.

To import data into the application you need to tell Pelican some important details:
@li The type of socket the stream is on
@li The host and port of the stream
@li How to chop the data into units for processing (Chunking the data)
@li How to interpret the data stream (Adapting the data)

To do this you will need to implement two c++ classes, one for the Chunking and
on for data Adaption. These classes then slot into the pelican framework to 
deliver your data according to your chosen @link user_framework_deploymentExamples deployment @endlink
options.

@subsection dataTypes Two types of Data
Inside the Data Importation framework, Pelican distinguishes between two classes of data, namely @b StreamData
and @b ServiceData.
There can be any number of StreamData and ServiceData types, but each one will need its own
Adapter and Chunker. It is also possible to have multiple inputs of the same type. Each
source of incoming data, either stream or service, must have its own unique identifier in the
form of an identifing string.

@subsubsection streamData StreamData 
                   This is an incoming data stream, that is expected to be a fairly continuous
                   series of similarly structured data. As it arrives it is automatically associated
                   with any available service data.

@subsubsection serviceData ServiceData. 
                   This is relatively static data that is updated occassionally and
                   supports the stream data. e.g. describing the 
                   incoming streams data format, or status information of instruments
                   collecting the data.
                   There is always a "current" version of any type of ServiceData
                   and it is this version that is associated with any incoming stream data.

This remainder of this section of the guide is
is intended for those who have to write a libary for the raw incoming data
streams. If this has already been done for you and the data stream you which to process then
you may want to skip to the @ref user_framework_pipelineEssentials section.

@section dataEssentials_adapters Creating an Adapter

A data Adapters role is to take an incoming bit stream and convert it in
to C++ class structures suitable for handing down to the processing Pipeline.
The Adapters must inherit from either the @em AbstractStreamAdapter, or the @em AbstractServiceAdapter class.
The data class it must fill should inherit from @em DataBlob. There are a number of existing DataBlob types
that can be used in the modules, so you may not necessarily have to create your own if these are suitable.

So lets create our own Adapter.

@include AdapterExample.cpp

@section dataEssentials_chunkers Creating a Data Chunker
The function of the chunker is to take an incoming data stream and turn it into
suitable size chunks that can be fed into the Data Adapter.

@include ChunkerExample.cpp

@section connecting_dataClientDirect Connecting Directly to a Datastream

@section connecting_dataClientServer Connecting to a Pelican Server

*/
